# -*- coding: utf-8 -*-
"""Untitled21.ipynbpt sentiment analysis

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UrLwyRNGW8FJMOuGAmuVTAdOmdFX50qp
"""



import pandas as pd
df = pd.read_csv('file.csv')
df = df.head(10000)

#eda

df.describe(include='object')

df.columns

df.drop(labels='Unnamed: 0',axis=1,inplace=True)

df.head



df.dtypes

df.info

df['labels'].unique()

df['tweets'].nunique()

import matplotlib.pyplot as plt
plt.style.use('ggplot')

ax = df['labels'].value_counts().sort_index().plot(kind='bar', title='Count of Different Sentiments',
                                                  figsize=(6,6))
ax.set_xlabel('Sentiments')
plt.show()

df['tweets'] = df['tweets'].str.split('https:')

df.labels.replace(['bad','neutral','good'],[-1.0,0.0,1.0], inplace=True)

df['input'] = 'TWEET:' + str(df.tweets.values)

pip install datasets

from datasets import Dataset, DatasetDict

ds = Dataset.from_pandas(df)

model_nm = 'microsoft/deberta-v3-small'

pip install transformers

pip install sentencepiece

from transformers import AutoTokenizer, AutoModelForSequenceClassification
tokz = AutoTokenizer.from_pretrained(model_nm)

def tok_function(x):
    return tokz(x['input'])

tok_ds=ds.map(tok_function, batched=True)

from sklearn.model_selection import train_test_split

## Seperating the dataframe into train and test dictionary
## I'll use the dataset for validation
dds = tok_ds.train_test_split(0.25,seed=42)
dds

from transformers import TrainingArguments, Trainer

##Setting up the Hyperparameters
## We can change the htperparameter to see how it changes the result.

bs = 16
epochs = 10
lr = 4e-6

pip install transformers[torch]

pip install accelerate -U

args = TrainingArguments('outputs', learning_rate =lr, warmup_ratio=0.001,
                        lr_scheduler_type = 'cosine', evaluation_strategy = 'epoch',
                        per_device_train_batch_size = bs, per_device_eval_batch_size  = bs*2,
                        num_train_epochs = epochs, weight_decay = 1e-6, report_to = "none")

import numpy as np
## to see the relation between the input and label
## I'll use the Pearson's coefficient

def corr(x,y): return np.corrcoef(x,y)[0][1]
def corr_d(eval_pred): return {'pearson': corr(*eval_pred)}

!pip install evaluate
import numpy as np
import evaluate

metric = evaluate.load("accuracy")

def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    return metric.compute(predictions=predictions, references=labels)

model = AutoModelForSequenceClassification.from_pretrained(model_nm,num_labels=3)
trainer = Trainer(model, args, train_dataset = dds['train'],
                 eval_dataset = dds['test'], tokenizer = tokz, compute_metrics=compute_metrics)

trainer.train()

trainer.evaluate()











